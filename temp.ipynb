{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.5000,  -3.6000,  69.0000,  39.0000,  99.8100],\n",
       "        [  1.5000,  -3.9000,  67.0000,  35.0000, 100.0100],\n",
       "        [  1.0000,  -4.3000,  68.0000,  32.0000, 100.1400],\n",
       "        ...,\n",
       "        [  4.0000,   3.6000,  97.0000,  32.0000,  99.1500],\n",
       "        [  4.0000,   3.6000,  97.0000,  30.0000,  98.8000],\n",
       "        [  4.0000,   3.7000,  98.0000,  15.0000,  98.5700]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from Network import *\n",
    "\n",
    "# 选取需要的列\n",
    "COLUMN_INDEX = [\n",
    "    \"Temp (°C)\",\n",
    "    \"Dew Point Temp (°C)\",\n",
    "    \"Rel Hum (%)\",\n",
    "    \"Wind Spd (km/h)\",\n",
    "    \"Stn Press (kPa)\",\n",
    "]\n",
    "data = pd.read_csv(\"Data/DataSet.csv\")[COLUMN_INDEX].to_numpy()\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATIO=0.7\n",
    "NUM_STEPS=48\n",
    "BATCH_SIZE=32\n",
    "\n",
    "def PERIOD_DATA(DATA,STARTING_INDEX,NUM_STEPS):\n",
    "    return DATA[STARTING_INDEX:STARTING_INDEX+NUM_STEPS,:]\n",
    "\n",
    "def TimeSeriesDataSplit(DATA,NUM_STEPS=None,RATIO=0.8,SHUFFLE=True):\n",
    "    if NUM_STEPS is None:\n",
    "        NUM_STEPS=7*24\n",
    "    if SHUFFLE:\n",
    "        INDEX=torch.randperm(DATA.shape[0]-NUM_STEPS)\n",
    "    else:\n",
    "        INDEX=torch.arange(0,DATA.shape[0]-NUM_STEPS)    \n",
    "    \n",
    "    TRAIN_SET_INDEX=INDEX[:int(RATIO*len(INDEX))]\n",
    "    TEST_SET_INDEX=INDEX[int(RATIO*len(INDEX)):]\n",
    "    TRAIN_SET_DATA=[PERIOD_DATA(DATA,index,NUM_STEPS) for index in TRAIN_SET_INDEX]\n",
    "    TEST_SET_DATA=[PERIOD_DATA(DATA,index,NUM_STEPS) for index in TEST_SET_INDEX]\n",
    "\n",
    "    return TRAIN_SET_DATA,TEST_SET_DATA,TRAIN_SET_INDEX,TEST_SET_INDEX\n",
    "\n",
    "def Data2Loader(DATA,INDEX,BATCH_SIZE,NUM_STEPS):\n",
    "    # Convert dataset to Dataloaders. Dataset elements are DATA[0].shape[1]\n",
    "    # \\times NUM_STEPS shaped tensors\n",
    "    NUM_SUBSEQUENCES=len(DATA)\n",
    "    NUM_BATCHES=NUM_SUBSEQUENCES//BATCH_SIZE\n",
    "    for i in range(NUM_BATCHES):\n",
    "        yield PERIOD_DATA(DATA,INDEX[i],NUM_STEPS),PERIOD_DATA(DATA,INDEX[i]+1,NUM_STEPS)\n",
    "# _,_,temp1,temp2=TimeSeriesDataSplit(DATA=data_tensor,NUM_STEPS=NUM_STEPS,RATIO=0.01)\n",
    "# temp3=Data2Loader(DATA=data_tensor,INDEX=temp1,BATCH_SIZE=BATCH_SIZE,NUM_STEPS=NUM_STEPS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeSeriesDataSplit2Loaders(DATA,BATCH_SIZE=None,NUM_STEPS=None,RATIO=0.8,SHUFFLE=True):\n",
    "    if BATCH_SIZE is None:\n",
    "        BATCH_SIZE=32\n",
    "    if NUM_STEPS is None:\n",
    "        NUM_STEPS=7*24\n",
    "    if SHUFFLE:\n",
    "        INDEX=torch.randperm(DATA.shape[0]-NUM_STEPS-1)\n",
    "    else:\n",
    "        INDEX=torch.arange(0,DATA.shape[0]-NUM_STEPS-1)\n",
    "    \n",
    "    TRAIN_SET_INDEX=INDEX[:int(RATIO*len(INDEX))]\n",
    "    TEST_SET_INDEX=INDEX[int(RATIO*len(INDEX)):]\n",
    "    TRAIN_SET_DATA_FORMMER=[PERIOD_DATA(DATA,index,NUM_STEPS) for index in TRAIN_SET_INDEX]\n",
    "    TRAIN_SET_DATA_LATTER=[PERIOD_DATA(DATA,index+1,NUM_STEPS) for index in TRAIN_SET_INDEX]\n",
    "    TEST_SET_DATA_FORMMER=[PERIOD_DATA(DATA,index,NUM_STEPS) for index in TEST_SET_INDEX]\n",
    "    TEST_SET_DATA_LATTER=[PERIOD_DATA(DATA,index+1,NUM_STEPS) for index in TEST_SET_INDEX]\n",
    "\n",
    "\n",
    "    return (DataLoader((TRAIN_SET_DATA_FORMMER,TRAIN_SET_DATA_LATTER)\n",
    "                       ,batch_size=BATCH_SIZE),\n",
    "            DataLoader((TEST_SET_DATA_FORMMER,TEST_SET_DATA_LATTER)\n",
    "                       ,batch_size=BATCH_SIZE),\n",
    "            TRAIN_SET_INDEX,TEST_SET_INDEX)\n",
    "\n",
    "train_loader,test_loader,train_index,test_index=TimeSeriesDataSplit2Loaders(\n",
    "    data_tensor,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    NUM_STEPS=NUM_STEPS,\n",
    "    RATIO=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=25\n",
    "next(iter(train_loader))[0][0,temp,:]==next(iter(train_loader))[0][1,temp-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"The RNN model.\n",
    "\n",
    "    Defined in :numref:`sec_rnn-concise`\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        # If the RNN is bidirectional (to be introduced later),\n",
    "        # `num_directions` should be 2, else it should be 1.\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # The fully connected layer will first change the shape of `Y` to\n",
    "        # (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is\n",
    "        # (`num_steps` * `batch_size`, `vocab_size`).\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # `nn.GRU` takes a tensor as hidden state\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # `nn.LSTM` takes a tuple of hidden states\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            weight.new( batch_size,self.n_layers, self.hidden_dim)\n",
    "            .zero_()\n",
    "        )\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GRUNet(input_dim=5,hidden_dim=8,output_dim=5,n_layers=2,drop_prob=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 5]), torch.Size([32, 2, 8]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0][0].shape,model.init_hidden(BATCH_SIZE).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_SingleProcessDataLoaderIter' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16120\\1619922118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1E-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# TRAIN_WITH_PROGRESS_BAR(MODEL=model,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '_SingleProcessDataLoaderIter' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1E-5)\n",
    "\n",
    "model(next(iter(train_loader)[0]),model.init_hidden(BATCH_SIZE))\n",
    "\n",
    "# TRAIN_WITH_PROGRESS_BAR(MODEL=model,\n",
    "#                         NUM_EPOCHS=1,\n",
    "#                         OPTIMIZER=optimizer,\n",
    "#                         TRAIN_LOADER=train_loader,\n",
    "#                         TEST_LOADER=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 8])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.init_hidden(BATCH_SIZE).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "batch_size=BATCH_SIZE\n",
    "\n",
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\",device=GET_DEVICE(0)):\n",
    "    \n",
    "    # Setting common hyperparameters\n",
    "    input_dim = 5\n",
    "    output_dim = 5\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "\n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "    model.train()\n",
    "    print(f\"Starting Training of {model_type} model\")\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "\n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if counter%1 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{EPOCHS} Done, Total Loss: {avg_loss / len(train_loader)}\"\n",
    "        )\n",
    "        print(f\"Time Elapsed for Epoch: {str(current_time - start_time)} seconds\")\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(f\"Total Training Time: {str(sum(epoch_times))} seconds\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CTC\\anaconda3\\envs\\d2l\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16120\\3488278673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgru_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"GRU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16120\\263862181.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, learn_rate, hidden_dim, EPOCHS, model_type, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"GRU\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
