{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用自编码器提取特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取筛选后的数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.5000,  -3.6000,  69.0000,  39.0000,  99.8100],\n",
       "        [  1.5000,  -3.9000,  67.0000,  35.0000, 100.0100],\n",
       "        [  1.0000,  -4.3000,  68.0000,  32.0000, 100.1400],\n",
       "        ...,\n",
       "        [  4.0000,   3.6000,  97.0000,  32.0000,  99.1500],\n",
       "        [  4.0000,   3.6000,  97.0000,  30.0000,  98.8000],\n",
       "        [  4.0000,   3.7000,  98.0000,  15.0000,  98.5700]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 选取需要的列\n",
    "COLUMN_INDEX = [\n",
    "    \"Temp (°C)\",\n",
    "    \"Dew Point Temp (°C)\",\n",
    "    \"Rel Hum (%)\",\n",
    "    \"Wind Spd (km/h)\",\n",
    "    \"Stn Press (kPa)\",\n",
    "]\n",
    "\n",
    "data = pd.read_csv(\"Data/DataSet.csv\")[COLUMN_INDEX].to_numpy()\n",
    "\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "data_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分测试集和训练集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader, random_split\n",
    "\n",
    "train_size = int(0.8 * data_tensor.shape[0])\n",
    "test_size = data_tensor.shape[0] - train_size\n",
    "train_dataset, test_dataset = random_split(\n",
    "    TensorDataset(data_tensor,data_tensor), [train_size, test_size]\n",
    ")\n",
    "\n",
    "BATCHSIZE=32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义Auto Encoder结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyAutoencoder                            [1, 5]                    --\n",
       "├─Sequential: 1-1                        [1, 2]                    --\n",
       "│    └─Linear: 2-1                       [1, 4]                    24\n",
       "│    └─ReLU: 2-2                         [1, 4]                    --\n",
       "│    └─BatchNorm1d: 2-3                  [1, 4]                    8\n",
       "│    └─Dropout: 2-4                      [1, 4]                    --\n",
       "│    └─Linear: 2-5                       [1, 2]                    10\n",
       "│    └─ReLU: 2-6                         [1, 2]                    --\n",
       "│    └─BatchNorm1d: 2-7                  [1, 2]                    4\n",
       "│    └─Dropout: 2-8                      [1, 2]                    --\n",
       "├─Sequential: 1-2                        [1, 5]                    --\n",
       "│    └─Linear: 2-9                       [1, 4]                    12\n",
       "│    └─ReLU: 2-10                        [1, 4]                    --\n",
       "│    └─BatchNorm1d: 2-11                 [1, 4]                    8\n",
       "│    └─Dropout: 2-12                     [1, 4]                    --\n",
       "│    └─Linear: 2-13                      [1, 5]                    25\n",
       "==========================================================================================\n",
       "Total params: 91\n",
       "Trainable params: 91\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Network import *\n",
    "from torchinfo import summary\n",
    "\n",
    "MyAE = MyAutoencoder(input_size=5, hidden_size_1=4, hidden_size_2=2, dropout_prob=0.05)\n",
    "MyAE.apply(init_weights)\n",
    "summary(MyAE, (1, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from Network import *\n",
    "\n",
    "def trainer(MODEL,NUM_EPOCHS,OPTIMIZER,TRAIN_LOADER,TEST_LOADER=None,LOSS_TYPE=nn.MSELoss(),DEVICE=0,GRAD_MAX=5):\n",
    "    print(\"PyTorch Version:\",torch.__version__)\n",
    "    device=GET_DEVICE(DEVICE)\n",
    "    print(\"Training on\",device)\n",
    "    print(\n",
    "        \"====================================Start training====================================\"\n",
    "    )\n",
    "    MODEL.to(device)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        with tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\"\n",
    "        ) as t:\n",
    "            for x, y in t:\n",
    "                # 前向传播\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = MODEL(x)\n",
    "                loss = LOSS_TYPE(output, y)\n",
    "\n",
    "                # 反向传播\n",
    "                OPTIMIZER.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # 梯度裁剪\n",
    "                clip_grad_norm_(MODEL.parameters(),GRAD_MAX)\n",
    "\n",
    "                OPTIMIZER.step()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "    print(\n",
    "        \"====================================Finish training====================================\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_temp(MODEL,NUM_EPOCHS,OPTIMIZER,TRAIN_LOADER,TEST_LOADER=None,LOSS_TYPE=nn.MSELoss(),DEVICE=0,GRAD_MAX=5):\n",
    "    print(\"PyTorch Version:\",torch.__version__)\n",
    "    device=GET_DEVICE(DEVICE)\n",
    "    print(\"Training on\",device)\n",
    "    print(\n",
    "        \"====================================Start training====================================\"\n",
    "    )\n",
    "    # 模型传递到指定设备上\n",
    "    MODEL.to(device)\n",
    "\n",
    "    # 记录训练误差和测试误差\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # 切换到train模式\n",
    "        MODEL.train()\n",
    "        LOSS_TRAIN=torch.tensor(0.0)\n",
    "        LOSS_TEST=torch.tensor(0,0)\n",
    "\n",
    "        # 根据训练集上的loss作梯度下降\n",
    "        with tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\"\n",
    "        ) as t:\n",
    "            for x, y in t:\n",
    "                # 前向传播\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = MODEL(x)\n",
    "                loss = LOSS_TYPE(output, y)\n",
    "\n",
    "                # 反向传播\n",
    "                OPTIMIZER.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # 梯度裁剪\n",
    "                clip_grad_norm_(MODEL.parameters(),GRAD_MAX)\n",
    "\n",
    "                OPTIMIZER.step()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "                LOSS_TRAIN+=loss.item()\n",
    "        \n",
    "        LOSS_TRAIN_AVERAGE=LOSS_TRAIN/len(train_loader)\n",
    "    print(\n",
    "        \"====================================Finish training====================================\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.11.0\n",
      "Training on cuda:0\n",
      "====================================Start training====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 438/438 [00:02<00:00, 167.97batch/s, loss=115]    \n",
      "Epoch 2/20: 100%|██████████| 438/438 [00:02<00:00, 167.46batch/s, loss=83.4]\n",
      "Epoch 3/20: 100%|██████████| 438/438 [00:03<00:00, 143.67batch/s, loss=52.2]\n",
      "Epoch 4/20: 100%|██████████| 438/438 [00:02<00:00, 149.49batch/s, loss=99.7]\n",
      "Epoch 5/20: 100%|██████████| 438/438 [00:02<00:00, 151.19batch/s, loss=98]  \n",
      "Epoch 6/20: 100%|██████████| 438/438 [00:02<00:00, 156.52batch/s, loss=93.6]\n",
      "Epoch 7/20: 100%|██████████| 438/438 [00:02<00:00, 156.86batch/s, loss=119] \n",
      "Epoch 8/20: 100%|██████████| 438/438 [00:02<00:00, 157.61batch/s, loss=59.8]\n",
      "Epoch 9/20: 100%|██████████| 438/438 [00:02<00:00, 153.38batch/s, loss=47.4]\n",
      "Epoch 10/20: 100%|██████████| 438/438 [00:02<00:00, 155.06batch/s, loss=78.8]\n",
      "Epoch 11/20: 100%|██████████| 438/438 [00:02<00:00, 154.28batch/s, loss=84]  \n",
      "Epoch 12/20: 100%|██████████| 438/438 [00:02<00:00, 154.89batch/s, loss=86.1]\n",
      "Epoch 13/20: 100%|██████████| 438/438 [00:02<00:00, 155.99batch/s, loss=38.9]\n",
      "Epoch 14/20: 100%|██████████| 438/438 [00:02<00:00, 154.75batch/s, loss=47.5]\n",
      "Epoch 15/20: 100%|██████████| 438/438 [00:02<00:00, 155.35batch/s, loss=52.3]\n",
      "Epoch 16/20: 100%|██████████| 438/438 [00:02<00:00, 153.27batch/s, loss=70.7]\n",
      "Epoch 17/20: 100%|██████████| 438/438 [00:02<00:00, 152.97batch/s, loss=39.7]\n",
      "Epoch 18/20: 100%|██████████| 438/438 [00:02<00:00, 173.31batch/s, loss=48.7]\n",
      "Epoch 19/20: 100%|██████████| 438/438 [00:02<00:00, 162.08batch/s, loss=63.4]\n",
      "Epoch 20/20: 100%|██████████| 438/438 [00:02<00:00, 158.59batch/s, loss=49.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================Finish training====================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(MyAE.parameters(), lr=0.01, weight_decay=1E-5)\n",
    "trainer(\n",
    "    MyAE,\n",
    "    NUM_EPOCHS=20,\n",
    "    OPTIMIZER=optimizer,\n",
    "    TRAIN_LOADER=train_loader,\n",
    "    LOSS_TYPE=nn.MSELoss(),\n",
    "    DEVICE=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
